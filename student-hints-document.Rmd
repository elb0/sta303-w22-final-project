---
title: "Student hints document"
output: html_notebook
---

# Skills

Students making a strong effort on this project will demonstrate the following skills:

## Statistical reasoning and knowledge

- Develop relevant research questions that can be explored/answered statistically.
- Merge large datasets programmatically and wrangle them appropriately to create meaningful new variables, where relevant.
- Choose and create appropriate data visualizations and summaries.
- Choose appropriate statistical models and check their assumptions.
- Justify choice of methods in writing.
- Accurately describe results, including size and direction of effect through confidence intervals, where relevant.
- Identify and discuss strengths and limitations of statistical approaches.

## Ethical profession practice
- Understand and put into their own words aspects of the Statistical Society of Canada Code of Ethical Statistical Practice. (Demonstrated through the code of conduct for your ‘company’.)
- Report findings truthfully and accurately, even when they are not what a stakeholder ‘wants to hear’.
- Identify potential sources of algorithmic bias.
- Working with and maintaining data privacy of licensed datasets. 
- Making thoughtful choices when dealing with social data (gender, ethnicity, age, etc.).
- Demonstrate appropriate ethical practices when webscraping.
- Demonstrate appropriate ehtical practices when accesing an API.
- Demonstrate basic familiarity with the concept of non-disclosure agreement.

## Modern data practices
- Access an API to retrieve a large volume of data.
- Scrape a table from a website into a usable dataset.
- Use a licensed postal code conversion file for data linkage.

## Writing

-   Write appropriately for different audiences, i.e. an executive summary for executives with limited statistical knowledge and a technical report for fellow analysts (though not assuming knowledge of R).
-   Format a report with a logical structure.
-   Work within length constraints to prioritize expressing the key information from a series of analyses.

## Programming

-   Create reproducible code and suppress code appropriately in a final 'human-readable' report. I.e., no error outputs in the final PDF or raw variable names used.
-   Use data wrangling and visualization functions and packages (largely `dplyr` and `ggplot2`.
-   Comment on and organize code logically.

## General

-   Construct and label tables and figures professionally.
-   Be resilient in the face of challenges, especially when it comes to troubleshooting code bugs.
-   Ask for help when they need it while also taking responsibility for their work.
-   Organize a data and analysis project with multiple required files and dataset.


# Getting census information from post codes

## Cancensus API

> "cancensus requires a valid CensusMapper API key to use. You can obtain a free API key by [signing up](https://censusmapper.ca/users/sign_up) for a CensusMapper account. CensusMapper API keys are free and public API quotas are generous; however, due to incremental costs of serving large quantities of data, there limits to API usage in place. For most use cases, these API limits should not be an issue." 
> ~Source: https://cran.r-project.org/web/packages/cancensus/vignettes/cancensus.html

- Sign up for the API through https://censusmapper.ca/users/sign_up
- Get your API key from the cancensus site.


## Postal code conversion file

- As a university of Toronto student you have access to a Census Canada [Postal Code Conversion Files](https://mdl.library.utoronto.ca/collections/numeric-data/census-canada/postal-code-conversion-file)

- Ethical considerations
  - You are asked to accept a license agreement to get access to this data.
  - This is data that should NOT go directly on to your GitHub. Think carefully about how you will process this data, saving only the information you need for any data that is part of your final submission.
- I recommend downloading the .sav file version. It says it is for SPSS, but it is easy to read into R.
- Choose an appropriate year and make sure you specify/judtify it in your write-up.
  
  
```{r}
# install.packages("haven")
library(haven)
dataset = read_sav("prof-data/pccfNat_fccpNat_082021sav.sav")

postcode <- dataset %>% 
  select(PC, CSDuid)

options(cancensus.api_key = "CensusMapper_8c6d18c4ef63dbfbe8c5ccb9c2f55871",
        cancensus.cache_path = "prof-data")  
```

# Wen scraping fitness tracker data



```{r}
# Note: In adapting this for your code, please ensure all libraries are in a setup chunk at the beginning

library(tidyverse)
library(polite)
library(rvest)

target <- bow(url = "https://fitnesstrackerinfohub.netlify.app/",
              user_agent = "liza.bolton@utoronto.ca for STA303/1002 project",
              force = TRUE)

html <- scrape(target)

device_data <- html %>% 
  html_elements("table") %>% 
  html_table()

```

